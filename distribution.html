<!DOCTYPE html>
<html>
  <head>
    <title>Distributional Semantics, Category Theory, and other recent readings</title>
    <style>
       h2 {font-family:'Verdana';}
       p {font-family:'Verdana';}
    </style>
  </head>
  <script src="https://cdn.jsdelivr.net/gh/ncase/nutshell@1.0.2/nutshell.js"></script>
  <body>
    <h2>Distributional Semantics</h2>
<p>- <a href="https://en.wikipedia.org/wiki/Distributional_semantics">:link to wikipedia article</a>
<p>- research area that develops and studies theories and methods for quantifying and <a href="#CategoryTheory"> :categorizing</a> semantic similarities between linguistic items based on their distributional properties in large samples of language data. </p>
<p>- the basic idea can be summed up in the <a href="#DistributionalHypothesis">:distributional hypothesis</a>. </p>
<p>- basis for the theory <a href="#SimilarityBasedGeneralization">:similarity-based generalization</a> in language learning. </p>
<p>- the more semantically similar two words are, the more distributionally similar they will be, and thus they tend to occur in similar linguistic contexts more. </p>

<h2>Distributional Hypothesis</h2> 
<p>- linguistic items with similar distributions have similar meanings. </p>
<p>- <a href="https://en.wikipedia.org/wiki/Distributionalism">:more on distributionalism</a></p>

<h2>Category Theory</h2> 
<p>- <a href="https://dippedrusk.com/posts/2022-08-08-category-theory/">:an introductory article about category theory</a></p>
<p>- fun fact: category theory is described as <a href="https://en.wikipedia.org/wiki/Abstract_nonsense">:abstract nonsense</a> by mathematicians</p>
  
<h2>Similarity-Based Generalization</h2>
<p>- the idea that children can figure out how to use words they've rarely encountered before by generalizing about their use from distributions of similar words. </p>  </body>
</html>
